{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Swalokal - Machine Learning"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwsXLPK0ax_p",
        "outputId": "3f44a8f5-fba5-4b68-a3c2-ca4f9d564dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_uagoC1cOeH",
        "outputId": "f8200af9-1125-47b8-9186-e582989978f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "• Using TensorFlow Version: 2.12.0\n",
            "• GPU Device Found.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from os import getcwd\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import shutil\n",
        "\n",
        "print(\"\\u2022 Using TensorFlow Version:\", tf.__version__)\n",
        "print('\\u2022 GPU Device Found.' if tf.test.is_gpu_available() else '\\u2022 GPU Device Not Found. Running on CPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlIx16jzbJ0S",
        "outputId": "43416b23-531e-4c7c-ce7e-86e2a8f445ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YUQ4_8LVh_ag"
      },
      "source": [
        "## Import MobileNetV2 as our Transfered Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lPZ80Q9ccyv",
        "outputId": "81da75c8-1a8d-4bad-f6c4-ae557e89a7f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4 with input size (224, 224) and output dimension 1280\n"
          ]
        }
      ],
      "source": [
        "module_selection = (\"mobilenet_v2\", 224, 1280)  # @param [\"(\\\"mobilenet_v2\\\", 224, 1280)\", \"(\\\"inception_v3\\\", 299, 2048)\"] {type:\"raw\", allow-input: true}\n",
        "handle_base, pixels, FV_SIZE = module_selection\n",
        "MODULE_HANDLE = \"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(\n",
        "    handle_base\n",
        ")\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\n",
        "    \"Using {} with input size {} and output dimension {}\".format(\n",
        "        MODULE_HANDLE, IMAGE_SIZE, FV_SIZE\n",
        "    )\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can change the model with several list at the first-commented line, but we decided to use mobilenet_v2 for this project."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hGZZ03XViSq2"
      },
      "source": [
        "## Import Dataset from Gdrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFFTWj14bJcy",
        "outputId": "e3b6a8a0-d9cf-4ed8-97de-97bb0731bbd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wrG7GPm9d9Qd"
      },
      "outputs": [],
      "source": [
        "path = os.path.join(os.getcwd(), \"gdrive\", \"My Drive\")\n",
        "datapath = os.path.join(path, \"Capstone\")\n",
        "train_path = os.path.join(datapath, \"train\")\n",
        "test_path = os.path.join(datapath, \"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SBy-Ww4Po13_",
        "outputId": "12c7e0a8-6bdd-4fd5-f047-285b0fa9d3c6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/Capstone/train'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_path"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MAbfQWmyibXB"
      },
      "source": [
        "## Data Augmentation for train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI73FT0NeWPY",
        "outputId": "8f4f3ea1-eb8d-44cb-bf2b-addae8384398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 461 images belonging to 3 classes.\n",
            "Found 56 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "BATCH_SIZE = 20\n",
        "IMG_SIZE = (200, 200)\n",
        "\n",
        "train_datagen= ImageDataGenerator(rescale=1./255.,\n",
        "                                     rotation_range=40,\n",
        "                                     width_shift_range=0.2,\n",
        "                                     height_shift_range=0.2,\n",
        "                                     shear_range=0.2,\n",
        "                                     zoom_range=0.2,\n",
        "                                     horizontal_flip=True,\n",
        "                                     fill_mode='nearest')\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255.)\n",
        "\n",
        "train_dataset = train_datagen.flow_from_directory(\n",
        "    train_path, shuffle=True, batch_size=BATCH_SIZE, target_size=IMG_SIZE\n",
        ")\n",
        "test_dataset = test_datagen.flow_from_directory(\n",
        "    test_path, shuffle=True, batch_size=BATCH_SIZE, target_size=IMG_SIZE\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5_fgKTbDirJy"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature extracting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "O3Oe6kfj4uTI"
      },
      "outputs": [],
      "source": [
        "do_fine_tuning = False  # @param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gG75CkKC5FfZ"
      },
      "outputs": [],
      "source": [
        "feature_extractor = hub.KerasLayer(\n",
        "    MODULE_HANDLE,\n",
        "    input_shape=IMAGE_SIZE + (3,),\n",
        "    output_shape=[FV_SIZE],\n",
        "    trainable=do_fine_tuning,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b1UCard6P7S",
        "outputId": "a39e2226-364f-4d12-94f7-e934f7681cb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 1280)              2257984   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 3843      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,261,827\n",
            "Trainable params: 3,843\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential(\n",
        "    [feature_extractor, tf.keras.layers.Dense(3, activation=\"softmax\")]\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (Optional) Unfreeze some layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "k7CvPylW6V_v"
      },
      "outputs": [],
      "source": [
        "NUM_LAYERS = 30  # @param {type:\"slider\", min:1, max:50, step:1}\n",
        "\n",
        "if do_fine_tuning:\n",
        "    feature_extractor.trainable = True\n",
        "\n",
        "    for layer in model.layers[-NUM_LAYERS:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "else:\n",
        "    feature_extractor.trainable = False"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6fCKrdlf6bfb"
      },
      "outputs": [],
      "source": [
        "if do_fine_tuning:\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.SGD(lr=0.002, momentum=0.9),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "else:\n",
        "    model.compile(\n",
        "        optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVsmEquG6oRm",
        "outputId": "974c8492-c2a7-4f11-e4dd-12204c6de3b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 111s 4s/step - loss: 0.9531 - accuracy: 0.5293 - val_loss: 0.5291 - val_accuracy: 0.8036\n",
            "Epoch 2/15\n",
            "24/24 [==============================] - 10s 435ms/step - loss: 0.5088 - accuracy: 0.8134 - val_loss: 0.3378 - val_accuracy: 0.9107\n",
            "Epoch 3/15\n",
            "24/24 [==============================] - 10s 433ms/step - loss: 0.3842 - accuracy: 0.8720 - val_loss: 0.2762 - val_accuracy: 0.9107\n",
            "Epoch 4/15\n",
            "24/24 [==============================] - 10s 432ms/step - loss: 0.3098 - accuracy: 0.8980 - val_loss: 0.2452 - val_accuracy: 0.9107\n",
            "Epoch 5/15\n",
            "24/24 [==============================] - 11s 443ms/step - loss: 0.2539 - accuracy: 0.9197 - val_loss: 0.1844 - val_accuracy: 0.9286\n",
            "Epoch 6/15\n",
            "24/24 [==============================] - 10s 438ms/step - loss: 0.2463 - accuracy: 0.9262 - val_loss: 0.1815 - val_accuracy: 0.9464\n",
            "Epoch 7/15\n",
            "24/24 [==============================] - 9s 393ms/step - loss: 0.2146 - accuracy: 0.9479 - val_loss: 0.1613 - val_accuracy: 0.9464\n",
            "Epoch 8/15\n",
            "24/24 [==============================] - 10s 399ms/step - loss: 0.1735 - accuracy: 0.9566 - val_loss: 0.2030 - val_accuracy: 0.9286\n",
            "Epoch 9/15\n",
            "24/24 [==============================] - 11s 462ms/step - loss: 0.1751 - accuracy: 0.9610 - val_loss: 0.1780 - val_accuracy: 0.9464\n",
            "Epoch 10/15\n",
            "24/24 [==============================] - 10s 435ms/step - loss: 0.1611 - accuracy: 0.9566 - val_loss: 0.1652 - val_accuracy: 0.9643\n",
            "Epoch 11/15\n",
            "24/24 [==============================] - 15s 640ms/step - loss: 0.1616 - accuracy: 0.9566 - val_loss: 0.1626 - val_accuracy: 0.9643\n",
            "Epoch 12/15\n",
            "24/24 [==============================] - 11s 446ms/step - loss: 0.1618 - accuracy: 0.9610 - val_loss: 0.2458 - val_accuracy: 0.8929\n",
            "Epoch 13/15\n",
            "24/24 [==============================] - 9s 376ms/step - loss: 0.1679 - accuracy: 0.9523 - val_loss: 0.1503 - val_accuracy: 0.9643\n",
            "Epoch 14/15\n",
            "24/24 [==============================] - 10s 440ms/step - loss: 0.1344 - accuracy: 0.9566 - val_loss: 0.1460 - val_accuracy: 0.9643\n",
            "Epoch 15/15\n",
            "24/24 [==============================] - 11s 440ms/step - loss: 0.1257 - accuracy: 0.9696 - val_loss: 0.1521 - val_accuracy: 0.9643\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 15\n",
        "\n",
        "hist = model.fit(train_dataset, epochs=EPOCHS, validation_data=test_dataset)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4StBLVJtjGti"
      },
      "source": [
        "## Save and Export the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "OPCoFwR46s4K"
      },
      "outputs": [],
      "source": [
        "SWALOKAL_SAVED_MODEL = \"swalokal_saved_model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "i47m2RoVjUay"
      },
      "outputs": [],
      "source": [
        "tf.saved_model.save(model, SWALOKAL_SAVED_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3f6OZcljgrW",
        "outputId": "cde27a61-01cb-4d40-fbbe-a3ccac41aefe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['keras_layer_input'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 224, 224, 3)\n",
            "      name: serving_default_keras_layer_input:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['dense'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 3)\n",
            "      name: StatefulPartitionedCall:0\n",
            "Method name is: tensorflow/serving/predict\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-29 03:43:00.283288: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "%%bash -s $SWALOKAL_SAVED_MODEL\n",
        "saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "9M_OdvWjjqPI"
      },
      "outputs": [],
      "source": [
        "loaded = tf.saved_model.load(SWALOKAL_SAVED_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dmc4SWaJjrmZ",
        "outputId": "19ffbc7b-1a45-4731-8781-4826a4fd12da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['serving_default']\n",
            "((), {'keras_layer_input': TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_layer_input')})\n",
            "{'dense': TensorSpec(shape=(None, 3), dtype=tf.float32, name='dense')}\n"
          ]
        }
      ],
      "source": [
        "print(list(loaded.signatures.keys()))\n",
        "infer = loaded.signatures[\"serving_default\"]\n",
        "print(infer.structured_input_signature)\n",
        "print(infer.structured_outputs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DUnirZ1Qjxni"
      },
      "source": [
        "## Convert The Model using TFLite's Converter"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save model to tflite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LjOQi1ANj74X"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(SWALOKAL_SAVED_MODEL)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WdeTQdIOkAbc"
      },
      "outputs": [],
      "source": [
        "tflite_model_file = \"converted_model.tflite\"\n",
        "\n",
        "with open(tflite_model_file, \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save model into .pb "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FK_gfEnVmScR",
        "outputId": "ac150673-158b-4317-b54a-86d0a42a3be7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.12275767 0.11284676 0.76439553]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"converted_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output from tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Test model on random input data.\n",
        "input_shape = input_details[0]['shape']\n",
        "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "interpreter.invoke()\n",
        "\n",
        "# Get output data\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(output_data)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Zip the whole model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nk3wybcOkBmA",
        "outputId": "d5ab375d-40e5-406e-b3db-cfa096632588"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/swalokal_saved_model.zip'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "shutil.make_archive(\"swalokal_saved_model\", \"zip\", \"swalokal_saved_model\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
